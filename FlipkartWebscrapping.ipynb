{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipkart Web Scapping using Python\n",
    "This is Reference Notebook which is useful to scrapp the datafrom E-commerce website like Flipkart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductList=['iphone 6','5','apple iphone 8','apple 9','apple iphone 6s plus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UrlFormation(list):\n",
    "            Product_URL=[]\n",
    "            for i in list:\n",
    "                Product_Name_List=i.split(\" \")\n",
    "                if(len(Product_Name_List)==1):\n",
    "                    Url='https://www.flipkart.com/search?q='+str(i)+'&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off'\n",
    "                    Product_URL.append(Url)\n",
    "                else:\n",
    "                    Count=len(Product_Name_List)-1\n",
    "                    Url1='%20'\n",
    "                    Url3=''\n",
    "                    for j in range(Count):\n",
    "                        Url2=str(Product_Name_List[j])+Url1\n",
    "                        Url3=Url2+Url3\n",
    "                    Url='https://www.flipkart.com/search?q='+str(Url3)+str(Product_Name_List[-1])+'&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off'\n",
    "                    Product_URL.append(Url)\n",
    "            return Product_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.flipkart.com/search?q=iphone%206&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off', 'https://www.flipkart.com/search?q=5&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off', 'https://www.flipkart.com/search?q=iphone%20apple%208&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off', 'https://www.flipkart.com/search?q=apple%209&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off', 'https://www.flipkart.com/search?q=6s%20iphone%20apple%20plus&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off']\n"
     ]
    }
   ],
   "source": [
    "Product_URL=UrlFormation(ProductList)\n",
    "print(Product_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "for k in range(0,len(Product_URL)):\n",
    "    resp=requests.get(Product_URL[k])\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    containers=soup.findAll(\"div\",{\"class\":\"col col-7-12\"})\n",
    "    for i in containers:\n",
    "        Abc=i.findAll(\"div\",{\"class\":\"hGSR34 _2beYZw\"})\n",
    "        fieldnames = ['Product_Name', 'Description','Ratings']\n",
    "        for j in Abc:\n",
    "            with open('names.csv', 'a') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({'Product_Name':i.div.text,'Description':i.text,'Ratings':j.text})\n",
    "                #writer.writerow('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in containers:\\n    Abc=i.findAll(\"div\",{\"class\":\"hGSR34 _2beYZw\"})\\n    for j in Abc:\\n        with open(\\'names.csv\\', \\'w\\') as csvfile:\\n            fieldnames = [\\'Product_Name\\', \\'Description\\',\\'Ratings\\']\\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n            writer.writerow({\\'Product_Name\\':i.div.text,\\'Description\\':i.text,\\'Ratings\\':j.text})'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in containers:\n",
    "    Abc=i.findAll(\"div\",{\"class\":\"hGSR34 _2beYZw\"})\n",
    "    for j in Abc:\n",
    "        with open('names.csv', 'w') as csvfile:\n",
    "            fieldnames = ['Product_Name', 'Description','Ratings']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow({'Product_Name':i.div.text,'Description':i.text,'Ratings':j.text})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
